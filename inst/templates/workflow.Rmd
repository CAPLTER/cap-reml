---
title: "capeml template"
author: "information manager"
date: Sys.Date()
output: html_document
editor_options: 
  chunk_output_type: console
---

# libraries

```{r libraries}
library(tidyverse)
library(capeml)
library(gioseml)
```


# otherEntity

```{r otherEntity, eval=TRUE}

otherEntityObject_OE <- create_otherEntity(
  targetFile = "file",
  description = "description")

```


# people

See the gioseml package for examples of creating people resources from scratch.

```{r people}

# creator(s) - required

cameron <- create_role(
  firstName = "cameron",
  lastName = "boehme",
  roleType = "creator")
fabio <- create_role(
  giosPersonId = 23857,
  roleType = "creator")

creators <- list(cameron, fabio)

# metadata provider - required

cameron <- create_role(
  firstName = "cameron",
  lastName = "boehme",
  roleType = "metadata")

metadataProvider <- list(cameron)

# associated party - optional
# takes the optional argument `projectRole` (default: "former project associate")
mark <- create_role(
  giosPersonId = 132,
  roleType = "associated")
nancy <- create_role(
  giosPersonId = 150,
  roleType = "associated")

associatedParty <- list(mark, nancy)


```

# keywords

```{r keywords}

# CAP IRTs for reference (be sure to include these as appropriate):
# https://sustainability.asu.edu/caplter/research/

write_keywords()
```

# methods

Methods are automatically read from a `methods.md` file in the project
directory. If more elaborate methods are required, e.g., to incorporate
provenance, use the enhancedMethods approach.

Use this extended approach of developing methods if provenance data are
required or there are multiple methods files, otherwise the `create_dateset()`
function will look for a methods.md file in the working directory (or a file
path and name can be passed).

## methods and provenance

```{r methods_provenance, eval=FALSE}

# methods from file tagged as markdown
main <- list(description = list(read_markdown("methods.md")))

library(EDIutils)

# provenance: naip
naip <- emld::as_emld(EDIutils::api_get_provenance_metadata("knb-lter-cap.623.1"))
naip$`@context` <- NULL
naip$`@type` <- NULL

# provenance: lst
landSurfaceTemp <- emld::as_emld(EDIutils::api_get_provenance_metadata("knb-lter-cap.677.1"))
landSurfaceTemp$`@context` <- NULL
landSurfaceTemp$`@type` <- NULL

enhancedMethods <- EML::eml$methods(methodStep = list(main, naip, landSurfaceTemp))

```

# coverages

```{r coverages}

# begindate <- format(min(runoff_chemistry$runoff_datetime), "%Y-%m-%d")
# enddate <- format(max(runoff_chemistry$runoff_datetime), "%Y-%m-%d")
geographicDescription <- "CAP LTER study area"
coverage <- set_coverage(
  begin = "2014-09-01",
  end = "2015-03-30",
  geographicDescription = geographicDescription,
  west = -112.100, east = -111.877,
  north = +33.608, south = +33.328)

```

## taxonomic coverage

Taxonomic coverage(s) are constructed using EDI's taxonomyCleanr tool suite.

*Note* that the `taxa_map.csv` built with the `create_taxa_map()` function and
resolving taxonomic IDs (i.e., `resolve_comm_taxa()`) only needs to be run once,
a potentially long process, per version/session -- the taxonomicCoverage can be
built as many times as needed with `resolve_comm_taxa()` once the `taxa_map.csv`
has been generated and the taxonomic IDs resolved.

```{r taxonomyCleanr, eval=FALSE}

library(taxonomyCleanr)

my_path <- getwd() # taxonomyCleanr requires a path (to build the taxa_map)

# Example: draw taxonomic information from existing resource:

# plant taxa listed in the om_transpiration_factors file
plantTaxa <- read_csv('om_transpiration_factors.csv') %>%
  filter(attributeName == "species") %>% 
  as.data.frame()

# create or update map. A taxa_map.csv is the heart of taxonomyCleanr. This
# function will build the taxa_map.csv and put it in the path identified with
# my_path.
create_taxa_map(path = my_path, x = plantTaxa, col = "definition")

# Example: construct taxonomic resource:

gambelQuail <- tibble(taxName = "Callipepla gambelii")

# Create or update map: a taxa_map.csv is the heart of taxonomyCleanr. This
# function will build the taxa_map.csv in the path identified with my_path.
create_taxa_map(path = my_path, x = gambelQuail, col = "taxName")

# Resolve taxa by attempting to match the taxon name (data.source 3 is ITIS but
# other sources are accessible). Use `resolve_comm_taxa` instead of
# `resolve_sci_taxa` if taxa names are common names but note that ITIS
# (data.source 3) is the only authority taxonomyCleanr will allow for common
# names.
resolve_sci_taxa(path = my_path, data.sources = 3) # in this case, 3 is ITIS

# build the EML taxonomomic coverage
taxaCoverage <- make_taxonomicCoverage(path = my_path)

# add taxonomic to the other coverages
coverage$taxonomicCoverage <- taxaCoverage
```

# dataset

Optionally, provide: scope, abstract, methods, keywords, publication date.
Projects scopes include lter (default), urex, ltreb, and som.

```{r construct-dataset}

dataset <- create_dataset()
```

# add dataTable

```{r dataSet$dataTable}

# add dataTables if relevant

print(ls(pattern = "_DT"))

if (length(ls(pattern = "_DT")) > 0) {

  listOfDataTables <- lapply(ls(pattern = "_DT"), function(DT) { get(DT) } )

  dataset$dataTable  <- listOfDataTables

}

# or add manually
# dataset$dataTable <- list(dataTableOne, dataTableTwo)

```

# add otherEntity

```{r dataSet$otherEntity}

# add other entities if relevant

print(ls(pattern = "_OE"))

if (length(ls(pattern = "_OE")) > 0) {

  listOfOtherEntities <- lapply(ls(pattern = "_OE"), function(OE) { get(OE) } )

  dataset$otherEntity <- listOfOtherEntities

}

# or add manually
# dataset$otherEntity <- list(otherEntityOne, otherEntityTwo)

```

# add spatialVector

```{r dataSet$spatialVector}

# add spatial vectors if relevant

print(ls(pattern = "_SV"))

if (length(ls(pattern = "_SV")) > 0) {

  listOfSpatialVectors <- lapply(ls(pattern = "_SV"), function(SV) { get(SV) } )

  dataset$spatialVector  <- listOfSpatialVectors

}

# or add manually
# dataset$spatialVector <- list(spatialVectorOne, spatialVectorTwo)

```

# customUnits

```{r custom-units, eval=FALSE}

custom_units <- rbind(
  data.frame(
    id = "milligramPerKilogram",
    unitType = "massPerMass",
    parentSI = "gramsPerGram",
    multiplierToSI = 0.000001,
    description = "millgram of element per kilogram of material")
)

unitList <- set_unitList(
  custom_units,
  as_metadata = TRUE)

```

# literature cited

```{r literature cited, eval=FALSE}

# add literature cited if relevant
middel_2019 <- create_citation("https://doi.org/10.1016/j.scitotenv.2019.06.085")
middel_2016 <- create_citation("https://doi.org/10.1007/s00484-016-1172-5")
thorsson <- create_citation("https://doi.org/10.1002/joc.1537")

citations <- list(
  citation = list(
    middel_2019,
    middel_2016,
    thorsson
  ) # close list of citations
) # close citation

dataset$literatureCited <- citations


```

# eml

```{r construct_eml, eval=TRUE}

eml <- create_eml()
```

```{r validate_eml, eval=TRUE}

eml_validate(eml)
```

```{r eml_to_file, eval=TRUE}

# write the eml to file
write_cap_eml()
```
